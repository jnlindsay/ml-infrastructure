{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Grid sequence autoencoder",
   "id": "4dee6b962d2c474d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Imports and constants",
   "id": "e5785f297d49ecf0"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-01T02:28:11.228963Z",
     "start_time": "2025-01-01T02:28:10.278424Z"
    }
   },
   "source": [
    "from trainers.grid_sequence_autoencoder_trainer import GridSequenceAutoencoderTrainer\n",
    "from utilities.grid import GridFactory\n",
    "import torch\n",
    "\n",
    "NUM_ROWS = 10\n",
    "NUM_COLS = 10"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Lines",
   "id": "76333767d7f6b6e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T02:31:18.932256Z",
     "start_time": "2025-01-01T02:28:12.838160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "grid_autoencoder_trainer = GridSequenceAutoencoderTrainer(10, 10)\n",
    "\n",
    "training_phases = [\n",
    "    GridSequenceAutoencoderTrainer.TrainingPhase(\"random_lines\", 1000, 30)\n",
    "]\n",
    "\n",
    "grid_autoencoder_trainer.train(training_phases, force_retrain=False)"
   ],
   "id": "54aeb2953c89dd58",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch 1, Loss: 0.0653\n",
      "Epoch 2, Loss: 0.0520\n",
      "Epoch 3, Loss: 0.0419\n",
      "Epoch 4, Loss: 0.0588\n",
      "Epoch 5, Loss: 0.0539\n",
      "Epoch 6, Loss: 0.0466\n",
      "Epoch 7, Loss: 0.0549\n",
      "Epoch 8, Loss: 0.0458\n",
      "Epoch 9, Loss: 0.0480\n",
      "Epoch 10, Loss: 0.0517\n",
      "Epoch 11, Loss: 0.0610\n",
      "Epoch 12, Loss: 0.0538\n",
      "Epoch 13, Loss: 0.0434\n",
      "Epoch 14, Loss: 0.0478\n",
      "Epoch 15, Loss: 0.0605\n",
      "Epoch 16, Loss: 0.0439\n",
      "Epoch 17, Loss: 0.0579\n",
      "Epoch 18, Loss: 0.0431\n",
      "Epoch 19, Loss: 0.0500\n",
      "Epoch 20, Loss: 0.0576\n",
      "Epoch 21, Loss: 0.0509\n",
      "Epoch 22, Loss: 0.0508\n",
      "Epoch 23, Loss: 0.0505\n",
      "Epoch 24, Loss: 0.0646\n",
      "Epoch 25, Loss: 0.0528\n",
      "Epoch 26, Loss: 0.0542\n",
      "Epoch 27, Loss: 0.0578\n",
      "Epoch 28, Loss: 0.0524\n",
      "Epoch 29, Loss: 0.0487\n",
      "Epoch 30, Loss: 0.0502\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T02:31:28.647040Z",
     "start_time": "2025-01-01T02:31:28.331734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "demo_grid_factory = GridFactory(NUM_ROWS, NUM_COLS)\n",
    "demo_grid = demo_grid_factory.generate_random_line().unsqueeze(0)\n",
    "grid_autoencoder_trainer.demonstrate(demo_example=demo_grid)"
   ],
   "id": "1da0de0f0e003ced",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[5, 1, 10, 10]' is invalid for input of size 100",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m demo_grid_factory \u001B[38;5;241m=\u001B[39m GridFactory(NUM_ROWS, NUM_COLS)\n\u001B[1;32m      2\u001B[0m demo_grid \u001B[38;5;241m=\u001B[39m demo_grid_factory\u001B[38;5;241m.\u001B[39mgenerate_random_line()\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m \u001B[43mgrid_autoencoder_trainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdemonstrate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdemo_example\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdemo_grid\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Programming/ml-infrastructure/src/trainers/grid_sequence_autoencoder_trainer.py:120\u001B[0m, in \u001B[0;36mGridSequenceAutoencoderTrainer.demonstrate\u001B[0;34m(self, type, demo_example, show_loss)\u001B[0m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m demo_example \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m: \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo demo example specified\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 120\u001B[0m     reconstructed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdemo_example\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munsqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# add batch dimension\u001B[39;00m\n\u001B[1;32m    122\u001B[0m original_grid \u001B[38;5;241m=\u001B[39m demo_example\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m    123\u001B[0m reconstructed_grid \u001B[38;5;241m=\u001B[39m reconstructed\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/Programming/ml-infrastructure/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Programming/ml-infrastructure/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Documents/Programming/ml-infrastructure/src/models/grid_autoencoder.py:165\u001B[0m, in \u001B[0;36mViTGridSequenceAutoencoder.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    161\u001B[0m current_frame \u001B[38;5;241m=\u001B[39m x[:, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]  \u001B[38;5;66;03m# Target frame\u001B[39;00m\n\u001B[1;32m    163\u001B[0m \u001B[38;5;66;03m# Process memory frames\u001B[39;00m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;66;03m# Reshape to process all frames at once\u001B[39;00m\n\u001B[0;32m--> 165\u001B[0m memory_frames \u001B[38;5;241m=\u001B[39m \u001B[43mmemory_frames\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmemory_length\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;66;03m# Patch embedding\u001B[39;00m\n\u001B[1;32m    168\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpatch_embed(memory_frames)  \u001B[38;5;66;03m# (batch*memory_length, hidden_dim, 25)\u001B[39;00m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: shape '[5, 1, 10, 10]' is invalid for input of size 100"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Lines ranker\n",
    "\n"
   ],
   "id": "58e941012c13014"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "grids = [\n",
    "    [\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    ],\n",
    "    [\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    ],\n",
    "    [\n",
    "        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
    "    ]\n",
    "]\n",
    "\n",
    "for grid in grids:\n",
    "    grid_autoencoder_trainer.demonstrate(\n",
    "        demo_example=torch.tensor(grid).to(torch.float).unsqueeze(0),\n",
    "        show_loss=True\n",
    "    )"
   ],
   "id": "b97c3e791c27ff0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Experiment: Non-symmetrical vs. symmetrical random grids",
   "id": "4e4fb0d95d8759a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Set up trainers and training phases",
   "id": "73aa25d764241fe3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "grid_autoencoder_trainer_symmetrical = GridAutoencoderTrainer(NUM_ROWS, NUM_COLS)\n",
    "\n",
    "training_phases_symmetrical = [\n",
    "    GridAutoencoderTrainer.TrainingPhase(\"random_symmetrical\", 1000, 50)\n",
    "]\n",
    "\n",
    "grid_autoencoder_trainer_symmetrical.train(training_phases_symmetrical, force_retrain=False)\n",
    "\n",
    "demo_grid_factory = GridFactory(NUM_ROWS, NUM_COLS)\n",
    "demo_grid = demo_grid_factory.generate_random_symmetrical().unsqueeze(0)\n",
    "\n",
    "grid_autoencoder_trainer_symmetrical.demonstrate(demo_example=demo_grid)"
   ],
   "id": "a66da916c93f6964",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
